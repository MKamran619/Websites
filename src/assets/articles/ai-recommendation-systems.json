{
  "id": "ai-recommendation-systems",
  "title": "Building Recommendation Systems That Actually Work",
  "excerpt": "Design and implement recommendation systems using collaborative filtering, content-based approaches, and hybrid methods with real-world considerations.",
  "date": "Aug 2023",
  "category": "AI & Machine Learning",
  "readTime": 13,
  "icon": "ðŸ¤–",
  "tags": ["Recommendations", "ML", "Personalization", "Python"],
  "featured": false,
  "author": {
    "name": "Kamran Sohail",
    "role": "Software Engineer & Consultant",
    "avatar": "KS"
  },
  "content": "<h2>Why Recommendations Matter</h2><p>Personalized recommendations drive engagement and revenue. Amazon attributes 35% of purchases to its recommendation engine. Netflix estimates recommendations save $1B annually in retention.</p><h2>Recommendation Approaches</h2><h3>Collaborative Filtering</h3><p>Recommend items based on similar users' preferences:</p><pre><code>import numpy as np\nfrom scipy.sparse import csr_matrix\nfrom sklearn.neighbors import NearestNeighbors\n\n# User-item matrix\nratings_matrix = csr_matrix(ratings_df.pivot(\n    index='user_id', \n    columns='item_id', \n    values='rating'\n).fillna(0))\n\n# Find similar users\nmodel = NearestNeighbors(metric='cosine', algorithm='brute')\nmodel.fit(ratings_matrix)\n\ndef get_recommendations(user_id, n=10):\n    user_vector = ratings_matrix[user_id]\n    distances, indices = model.kneighbors(user_vector, n_neighbors=20)\n    \n    # Aggregate ratings from similar users\n    similar_users_ratings = ratings_matrix[indices.flatten()].mean(axis=0)\n    \n    # Filter already rated items\n    user_rated = set(ratings_df[ratings_df.user_id == user_id].item_id)\n    recommendations = [\n        (i, score) for i, score in enumerate(similar_users_ratings.A1)\n        if i not in user_rated\n    ]\n    \n    return sorted(recommendations, key=lambda x: -x[1])[:n]</code></pre><h3>Content-Based Filtering</h3><p>Recommend items similar to what user liked before:</p><pre><code>from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Create item profiles from descriptions\nvectorizer = TfidfVectorizer(stop_words='english')\nitem_profiles = vectorizer.fit_transform(items_df['description'])\n\ndef content_recommendations(liked_item_ids, n=10):\n    # Create user profile from liked items\n    user_profile = item_profiles[liked_item_ids].mean(axis=0)\n    \n    # Find similar items\n    similarities = cosine_similarity(user_profile, item_profiles).flatten()\n    \n    # Exclude already liked items\n    recommendations = [\n        (i, sim) for i, sim in enumerate(similarities)\n        if i not in liked_item_ids\n    ]\n    \n    return sorted(recommendations, key=lambda x: -x[1])[:n]</code></pre><h3>Hybrid Approach</h3><pre><code>def hybrid_recommendations(user_id, liked_items, n=10):\n    # Get both types of recommendations\n    collab_recs = get_recommendations(user_id, n=n*2)\n    content_recs = content_recommendations(liked_items, n=n*2)\n    \n    # Combine with weights\n    scores = {}\n    for item_id, score in collab_recs:\n        scores[item_id] = scores.get(item_id, 0) + 0.6 * score\n    for item_id, score in content_recs:\n        scores[item_id] = scores.get(item_id, 0) + 0.4 * score\n    \n    return sorted(scores.items(), key=lambda x: -x[1])[:n]</code></pre><h2>Deep Learning Approaches</h2><h3>Neural Collaborative Filtering</h3><pre><code>import torch\nimport torch.nn as nn\n\nclass NCF(nn.Module):\n    def __init__(self, num_users, num_items, embedding_dim=64):\n        super().__init__()\n        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n        self.fc_layers = nn.Sequential(\n            nn.Linear(embedding_dim * 2, 128),\n            nn.ReLU(),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Linear(64, 1)\n        )\n        \n    def forward(self, user_ids, item_ids):\n        user_embed = self.user_embedding(user_ids)\n        item_embed = self.item_embedding(item_ids)\n        concat = torch.cat([user_embed, item_embed], dim=-1)\n        return self.fc_layers(concat).squeeze()</code></pre><h2>Production Considerations</h2><h3>Cold Start Problem</h3><ul><li>New users: Use content-based or popularity</li><li>New items: Use content similarity</li><li>Collect implicit feedback quickly</li></ul><h3>Real-Time vs Batch</h3><ul><li>Batch: Pre-compute recommendations daily</li><li>Real-time: Update based on session activity</li><li>Hybrid: Batch base + real-time adjustment</li></ul><h2>Evaluation Metrics</h2><ul><li><strong>Precision@K:</strong> Relevant items in top K</li><li><strong>Recall@K:</strong> Coverage of relevant items</li><li><strong>NDCG:</strong> Ranking quality</li><li><strong>A/B Testing:</strong> Business metrics (CTR, conversion)</li></ul><h2>Conclusion</h2><p>Start simple with collaborative filtering, add content-based for cold start, and evolve to deep learning as your data grows. Always validate with A/B tests.</p>"
}
